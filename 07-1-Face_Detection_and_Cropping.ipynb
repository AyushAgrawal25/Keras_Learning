{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cropFaces(imgPath, croppedFacesFolderPath):\n",
    "#     imgName=os.path.basename(imgPath)\n",
    "#     # Read image\n",
    "#     img=cv2.imread(imgPath)\n",
    "\n",
    "#     # Detect faces\n",
    "#     faceCascade=cv2.CascadeClassifier('/Coding/Learning/DL_Learning/Saved_Models/FaceDetection_Classifiers/haarcascade_frontalface_default.xml')\n",
    "#     faces=faceCascade.detectMultiScale(img,1.1,4)\n",
    "\n",
    "#     # Crop faces\n",
    "#     count=1;\n",
    "#     for (x,y,w,h) in faces:\n",
    "#         crop_img=img[y:y+h,x:x+w]\n",
    "\n",
    "#         # Check and create cropped faces folder\n",
    "#         if not os.path.exists(croppedFacesFolderPath):\n",
    "#             os.makedirs(croppedFacesFolderPath)\n",
    "\n",
    "#         # Save cropped faces\n",
    "#         croppedFaceName=imgName+'_face.'+str(count)+'.jpg'\n",
    "#         cv2.imwrite(os.path.join(croppedFacesFolderPath, croppedFaceName), crop_img)  \n",
    "#         count+=1\n",
    "\n",
    "#     return count\n",
    "\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Detech faces using MTCNN\n",
    "def cropFaces(imgPath, croppedFacesFolderPath):\n",
    "    imgName=os.path.basename(imgPath)\n",
    "    # Read image\n",
    "    img=cv2.imread(imgPath)\n",
    "\n",
    "    # Detect faces\n",
    "    detector=MTCNN()\n",
    "    faces=detector.detect_faces(img)\n",
    "\n",
    "    # Crop faces\n",
    "    count=1;\n",
    "    for face in faces:\n",
    "        x,y,w,h=face['box']\n",
    "        crop_img=img[y:y+h,x:x+w]\n",
    "\n",
    "        # Save cropped faces\n",
    "        croppedFaceName=imgName+'_face.'+str(count)+'.jpg'\n",
    "        cv2.imwrite(os.path.join(croppedFacesFolderPath, croppedFaceName), crop_img)  \n",
    "        count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n"
     ]
    }
   ],
   "source": [
    "imgFolderPath='/Coding/Learning/DL_Learning/Images/Group_Images/';\n",
    "imgName='group.image.06.jpg'\n",
    "imgPath=os.path.join(imgFolderPath,imgName)\n",
    "\n",
    "croppedFacesFolderPath=os.path.join(imgFolderPath,'Cropped_Faces');\n",
    "\n",
    "cropFaces(imgPath, croppedFacesFolderPath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Alignment (Dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trignometry_for_distance(a, b):\n",
    "#     return math.sqrt(((b[0] - a[0]) * (b[0] - a[0])) +\\\n",
    "#                      ((b[1] - a[1]) * (b[1] - a[1])))\n",
    "                     \n",
    "# def alignFace(imgPath):\n",
    "#     # Read image\n",
    "#     img=cv2.imread(imgPath)\n",
    "#     raw_img=img.copy()\n",
    "\n",
    "#     # Detect Face\n",
    "#     detector=MTCNN()\n",
    "#     faces = detector.detect_faces(img)\n",
    "#     if len(faces) !=1:\n",
    "#         return\n",
    "\n",
    "#     face=faces[0]['box']\n",
    "#     # Align Face\n",
    "#     face_img=img[face[1]:face[1]+face[3],face[0]:face[0]+face[2]]\n",
    "#     gray_img=cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # Detect Eyes\n",
    "#     eyeCascade=cv2.CascadeClassifier('/Coding/Learning/DL_Learning/Saved_Models/FaceDetection_Classifiers/haarcascade_eye.xml')\n",
    "#     eyes=eyeCascade.detectMultiScale(gray_img)\n",
    "\n",
    "#     if len(eyes)<2:\n",
    "#         return \n",
    "\n",
    "#     # Align Eyes\n",
    "#     eye = eyes[:, 2]\n",
    "#     container=[]\n",
    "#     for i in range(len(eye)):\n",
    "#         container.append((eye[i],i))\n",
    "    \n",
    "#     df=pd.DataFrame(container, columns=['length','index']).sort_values(by=['length'])\n",
    "#     eyes=eyes[df['index'].values[0:2]]\n",
    "    \n",
    "#     # Deciding to choose left or right eye\n",
    "#     eye_1 = eyes[0]\n",
    "#     eye_2 = eyes[1]\n",
    "#     if eye_1[0] > eye_2[0]:\n",
    "#         left_eye = eye_2\n",
    "#         right_eye = eye_1\n",
    "#     else:\n",
    "#         left_eye = eye_1\n",
    "#         right_eye = eye_2\n",
    "\n",
    "#     # Center of eyes\n",
    "#     # Center of right eye\n",
    "#     right_eye_center = (int(right_eye[0] + (right_eye[2]/2)), int(right_eye[1] + (right_eye[3]/2)))\n",
    "#     right_eye_x = right_eye_center[0]\n",
    "#     right_eye_y = right_eye_center[1]\n",
    "#     cv2.circle(img, right_eye_center, 2, (255, 0, 0), 3)\n",
    "\n",
    "#     # Center of left eye\n",
    "#     left_eye_center = (int(left_eye[0] + (left_eye[2] / 2)), int(left_eye[1] + (left_eye[3] / 2)))\n",
    "#     left_eye_x = left_eye_center[0]\n",
    "#     left_eye_y = left_eye_center[1]\n",
    "#     cv2.circle(img, left_eye_center, 2, (255, 0, 0), 3)\n",
    "    \n",
    "#     # Finding Rotation Direction\n",
    "#     if left_eye_y > right_eye_y:\n",
    "#         print(\"Rotate image to clock direction\")\n",
    "#         point_3rd = (right_eye_x, left_eye_y)\n",
    "#         direction = -1  # rotate image direction to clock\n",
    "#     else:\n",
    "#         print(\"Rotate to inverse clock direction\")\n",
    "#         point_3rd = (left_eye_x, right_eye_y)\n",
    "#         direction = 1  # rotate inverse direction of clock\n",
    "        \n",
    "#     cv2.circle(gray_img, point_3rd, 2, (255, 0, 0), 2)\n",
    "#     a = trignometry_for_distance(left_eye_center, point_3rd)\n",
    "#     b = trignometry_for_distance(right_eye_center, point_3rd)\n",
    "#     c = trignometry_for_distance(right_eye_center, left_eye_center)\n",
    "    \n",
    "#     cos_a = (b*b + c*c - a*a)/(2*b*c)\n",
    "#     angle = (np.arccos(cos_a) * 180) / math.pi\n",
    " \n",
    "#     if direction == -1:\n",
    "#         angle = 90 - angle\n",
    "#     else:\n",
    "#         angle = -(90-angle)\n",
    "    \n",
    "#     # Rotate image\n",
    "#     new_img=Image.fromarray(raw_img)\n",
    "#     new_img=new_img.rotate(angle, expand=True)\n",
    "\n",
    "#     # plt.imshow(new_img)\n",
    "#     return new_img\n",
    "    \n",
    "# imgPath='/Coding/Learning/DL_Learning/Images/Group_Images/Cropped_Faces/group.image.06.jpg_face.1.jpg'\n",
    "# alignFace(imgPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a81af83e9896d07241cbb362b0510c365a54d0c08254bf862d64fa80a66b9cc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
